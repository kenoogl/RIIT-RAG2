chat:
  cleanup_interval_hours: 24
  max_history_size: 50
  max_session_age_days: 30
llm:
  default_model: llama2:7b
  models:
    codellama:7b:
      context_window: 16384
      max_tokens: 4096
      temperature: 0.1
      top_p: 0.95
    llama2:7b:
      context_window: 4096
      max_tokens: 2048
      temperature: 0.7
      top_p: 0.9
  ollama_url: http://localhost:11434
rag:
  chunk_overlap: 200
  chunk_size: 1000
  max_context_docs: 5
  max_retrieved_docs: 10
  similarity_threshold: 0.7
system:
  disk_threshold_percent: 90
  log_level: INFO
  log_retention_days: 30
  max_log_size_mb: 100
  memory_threshold_percent: 80
web:
  cors_origins:
  - '*'
  host: 0.0.0.0
  port: 8000
  request_timeout: 300
